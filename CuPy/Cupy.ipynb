{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Computing with [CuPy](https://cupy.chainer.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy in a Nutshell\n",
    "\n",
    "* CuPy is a matrix library accelerated with [NVIDIA CUDA](https://developer.nvidia.com/cuda-zone). Using [CUDA-related GPU-accelerated libraries](https://developer.nvidia.com/gpu-accelerated-libraries) (cuBLAS, cuDNN, cuRand, cuSolver, cuSPARSE, cuFFT, NCCL) it allows to take full advantage of the computing power of GPUs.\n",
    "* CuPy's core component is the `cupy.ndarray` class which is highly compatible with `numpy.ndarray`.\n",
    "* It supports most of the high level operations of `NumPy` arrays and allows to write user defined kernels to execute on the GPU.\n",
    "* CuPy produces GPU kernels optimized for the shapes and dtypes of given arguments on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "# cp.cuda.set_allocator(None) # You can disable CuPy memory pool with this \n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "@contextmanager\n",
    "def cupy_timer():\n",
    "    start = cp.cuda.Event()\n",
    "    end = cp.cuda.Event()\n",
    "    start.record()\n",
    "    yield\n",
    "    end.record()\n",
    "    end.synchronize()\n",
    "    elapsed_time = cp.cuda.get_elapsed_time(start, end)\n",
    "    print(f'Elapsed time: {elapsed_time} ms')\n",
    "    \n",
    "\n",
    "@contextmanager\n",
    "def cpu_timer():\n",
    "    start = time()\n",
    "    yield\n",
    "    end = time()\n",
    "    print(f'Elapsed time: {(end - start) * 1000} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CuPy arrays directly on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cp.zeros((1000, 1000))\n",
    "print(f'Array A is of type: {type(A)}')\n",
    "\n",
    "B = cp.array([[1, 2, 3], \n",
    "              [4, 5, 6]])\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = cp.random.random((1000, 1000))\n",
    "mu = B.mean()\n",
    "print(f'The mean value is: {mu}')\n",
    "print(f'The type of mu is: {type(mu)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferring Arrays from Host to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_cpu = np.random.random((1000, 1000))\n",
    "A_gpu = cp.array(A_cpu)\n",
    "mu_cpu = A_cpu.mean()\n",
    "mu_gpu = A_gpu.mean()\n",
    "print(f'Mean using CPU: {mu_cpu}')\n",
    "print(f'Mean using GPU: {mu_gpu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranferring CuPy arrays to Host\n",
    "\n",
    "Tranferring of CuPy arrays to host is performed using the `cupy.ndarrray.get` method or the `cupy.asnumpy` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gpu = cp.ones((1000, 1000))\n",
    "x_cpu = x_gpu.get()\n",
    "print(f'Type of CPU array is: {type(x_cpu)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gpu = cp.random.random((1000, 1000))\n",
    "y_cpu = cp.asnumpy(y_gpu)\n",
    "print(f'Type of CPU array is: {type(y_cpu)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical CuPy Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cpu = np.random.random((1000, 1000))\n",
    "y_cpu = np.random.random((1000, 1000))\n",
    "x_gpu = cp.array(x_cpu)\n",
    "y_gpu = cp.array(y_cpu)\n",
    "\n",
    "with cpu_timer():\n",
    "    z_cpu = x_cpu @ y_cpu\n",
    "\n",
    "with cupy_timer():\n",
    "    z_gpu = x_gpu @ y_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear System Solving NumPy vs CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_cpu = np.random.random((10000, 10000))\n",
    "b_cpu = np.random.random(10000)\n",
    "A_gpu = cp.array(A_cpu)\n",
    "b_gpu = cp.array(b_cpu)\n",
    "with cpu_timer():\n",
    "    np.linalg.solve(A_cpu, b_cpu)\n",
    "    \n",
    "with cupy_timer():\n",
    "    cp.linalg.solve(A_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance matrix\n",
    "\n",
    "$\n",
    "    d_e(\\mathbf x, \\mathbf y) =\n",
    "    \\begin{bmatrix}\n",
    "    \\sum_{i=1}^n (x_{1i}-y_{1i})^2 & \\sum_{i=1}^n(x_{1i}-y_{2i})^2 & \\cdots & \\sum_{i=1}^n (x_{1i}-y_{ni})^2 \\\\  \n",
    "    \\sum_{i=1}^n(x_{2i}-y_{1i})^2 & \\sum_{i=1}^n(x_{2i}-y_{2i})^2 & \\cdots & \\sum_{i=1}^n(x_{2i}-y_{ni})^2 \\\\  \n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\sum_{i=1}^n(x_{ni}-y_{1i})^2 & \\sum_{i=1}^n(x_{ni}-y_{2i})^2 & \\cdots & \\sum_{i=1}^n(x_{ni}-y_{ni})^2 \\\\  \n",
    "    \\end{bmatrix}\n",
    "$\n",
    "\n",
    "## Vectorization friendly summation \n",
    "$ \n",
    "\\sum_{k=1}^n \\left(x_{ik}-y_{jk}\\right)^2 = \\left(\\vec{x_i} - \\vec {y_j}\\right)\\cdot \\left(\\vec{x_i} - \\vec{y_j}\\right)=\\vec{x_i} \\cdot \\vec{x_i} + \\vec{y_j} \\cdot \\vec{y_j} -2\\vec{x_i}\\cdot \\vec{y_j}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_cpu(x, y):\n",
    "    x2 = np.einsum('ij,ij->i', x, x)[:, np.newaxis]\n",
    "    y2 = np.einsum('ij,ij->i', y, y)[np.newaxis, :]\n",
    "    xy = x @ y.T\n",
    "    return np.abs(x2 + y2 - 2.0 * xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_gpu(x, y):\n",
    "    x2 = cp.einsum('ij,ij->i', x, x)[:, cp.newaxis]\n",
    "    y2 = cp.einsum('ij,ij->i', y, y)[cp.newaxis, :]\n",
    "    xy = x @ y.T\n",
    "    return cp.abs(x2 + y2 - 2.0 * xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cpu = np.random.random((5000, 5000))\n",
    "y_cpu = np.random.random((5000, 5000))\n",
    "x_gpu = cp.array(x_cpu)\n",
    "y_gpu = cp.array(y_cpu)\n",
    "\n",
    "with cpu_timer():\n",
    "    eu_cpu = euclidean_distance_cpu(x_cpu, y_cpu)\n",
    "\n",
    "with cupy_timer():\n",
    "    eu_gpu = euclidean_distance_gpu(x_gpu, y_gpu)\n",
    "    \n",
    "print(np.allclose(eu_cpu, eu_gpu.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make function work for both CuPy/NumPy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    array_mod = cp.get_array_module(x)\n",
    "    x2 = array_mod.einsum('ij,ij->i', x, x)[:, array_mod.newaxis]\n",
    "    y2 = array_mod.einsum('ij,ij->i', y, y)[array_mod.newaxis, :]\n",
    "    xy = x @ y.T\n",
    "    return array_mod.abs(x2 + y2 - 2.0 * xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cpu_timer():\n",
    "    eu_cpu = euclidean_distance(x_cpu, y_cpu)\n",
    "\n",
    "with cupy_timer():\n",
    "    eu_gpu = euclidean_distance(x_gpu, y_gpu)\n",
    "    \n",
    "print(np.allclose(eu_cpu, eu_gpu.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating/Plotting [Julia Sets](https://en.wikipedia.org/wiki/Julia_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "# distutils: extra_compile_args = -fopenmp -march=native\n",
    "# distutils: extra_link_args = -fopenmp\n",
    "from cython cimport boundscheck, wraparound\n",
    "from cython.parallel cimport prange\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def julia_set_cython(const double[:, :] X, const double[:, :] Y,\n",
    "                     const double cx, const double cy,\n",
    "                     const int iter_max, const double radius2, \n",
    "                     int[:, :] julia):\n",
    "    cdef:\n",
    "        int i, j, k, nx, ny\n",
    "        double x, y\n",
    "    nx = X.shape[0]\n",
    "    ny = Y.shape[1]\n",
    "    for i in prange(nx, nogil=True, schedule='static'):\n",
    "        for j in range(ny):\n",
    "            x = X[i, j]\n",
    "            y = Y[i, j]\n",
    "            k = 0\n",
    "            while x * x + y * y < radius2 and k < iter_max:\n",
    "                x, y = x * x - y * y + cx, 2.0 * x * y + cy\n",
    "                k = k + 1\n",
    "                \n",
    "            julia[i, j] = k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.linspace(-2.0 , 2.0, 5000), np.linspace(-2.0, 2.0, 5000))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "julia = np.zeros_like(X, dtype=np.int32)\n",
    "c = -0.9 + 0.22143j\n",
    "radius2 = 4.0\n",
    "with cpu_timer():\n",
    "    julia_set_cython(X, Y, c.real, c.imag, 100, radius2, julia)\n",
    "ax.set_aspect('equal')\n",
    "ax.imshow(julia, extent=[-2, 2, -2, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise Kernel\n",
    "\n",
    "Using the `cupy.ElementwiseKernel` class it is easy to create GPU kernels by defining the computation that is going to be applied to each element of the input array(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julia_kernel = cp.ElementwiseKernel('float64 X, float64 Y, float64 cx, float64 cy, int32 itermax, float64 radius2',\n",
    "                                    'int32 julia',\n",
    "                                    f'''julia = 0;\n",
    "                                    double x = X, y = Y;\n",
    "                                    double xtemp;\n",
    "                                    int nit = 0;\n",
    "                                    while(x * x + y * y < radius2 && nit < itermax) {{\n",
    "                                        xtemp = x * x - y * y + cx;\n",
    "                                        y = 2.0 * x * y + cy;\n",
    "                                        x = xtemp;\n",
    "                                        nit += 1;\n",
    "                                    }}\n",
    "                                    julia = nit;''', 'julia_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = cp.meshgrid(cp.linspace(-2.0 , 2.0, 5000), cp.linspace(-2.0, 2.0, 5000))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "c = -0.9 + 0.22143j\n",
    "with cupy_timer():\n",
    "    julia_gpu = julia_kernel(X, Y, c.real, c.imag, 100, 4.0)\n",
    "    julia_array = julia_gpu.get()\n",
    "ax.set_aspect('equal')\n",
    "ax.imshow(julia_array, extent=[-2, 2, -2, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Kernel\n",
    "\n",
    "It is possible to create raw CUDA kernels using the `cupy.RawKernel` class but the block and grid dimensions are not handled automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julia_rawkernel = cp.RawKernel(r'''\n",
    "        extern \"C\" \n",
    "        __global__ void julia_rawkernel(const double* X, const double* Y, const double cx,\n",
    "                              const double cy, const int itermax, const int nx,\n",
    "                              const int ny, const double radius, int* julia)  {\n",
    "        int tidx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        int tidy = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "        int niter = 0;\n",
    "        double tempx;\n",
    "        if(tidx < nx && tidy < ny) \n",
    "        {\n",
    "            int tid = tidy * nx + tidx;\n",
    "            double x = X[tid], y = Y[tid];\n",
    "            while((x * x + y * y) < (radius * radius) && niter < itermax) {\n",
    "                tempx = x * x - y * y + cx;\n",
    "                y = 2.0 * x * y + cy;\n",
    "                x = tempx;\n",
    "                niter +=1 ;\n",
    "            }\n",
    "            julia[tid] = niter;\n",
    "        }\n",
    "    }''', 'julia_rawkernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "c = -0.9 + 0.22143j\n",
    "threads_x = 32\n",
    "threads_y = 32\n",
    "x_points = 5000\n",
    "y_points = 5000\n",
    "x_blocks = (x_points - 1) // threads_x + 1 \n",
    "y_blocks = (y_points - 1) // threads_y + 1\n",
    "X_gpu, Y_gpu = cp.meshgrid(cp.linspace(-2.0 , 2.0, x_points), cp.linspace(-2.0, 2.0, y_points))\n",
    "with cupy_timer():\n",
    "    julia_gpu = cp.zeros_like(X_gpu, dtype=cp.int32)\n",
    "    julia_rawkernel((x_blocks, y_blocks), (threads_x, threads_y), (X_gpu, Y_gpu, c.real, c.imag, 100, \n",
    "                    x_points, y_points, 2.0, julia_gpu))\n",
    "    julia_array = julia_gpu.get()\n",
    "ax.imshow(julia_array, extent=[-2, 2, -2, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy Memory Pools \n",
    "\n",
    "In order to improve performance, CuPy uses a memory pool for memory allocations by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mempool = cp.get_default_memory_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_gbs = mempool.used_bytes() / 1024 ** 3\n",
    "total_gbs = mempool.total_bytes() / 1024 ** 3\n",
    "print(f'Memory pool uses: {used_gbs:.3f} out of {total_gbs:.3f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mempool.free_all_blocks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
