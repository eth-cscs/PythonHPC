{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Cityblock distance matrix function with SciPy and Dask's delayed execution\n",
    "\n",
    "In this notebook we use the function `scipy.spatial.distance.cdist` to compute the cityblock distance matrix. Althought this function is quite fast, it uses a single thread. In cases like this one, it might be convenient to implement a multithreaded version of the function by parallelicing the execution over chunks of data.\n",
    "\n",
    "<mark>Question</mark>: This notebook has the chunk-based implementation, but the parallelization is missing. This chunk-based calculation is pointless if there is no the parallelization: Use `dask.delayed` to compute all chunks in parallel and speed up the calculation.\n",
    "\n",
    "The notebook has no indications of where the modifications need to be done. Just follow the cells and identify what needs to be changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from dask import compute, delayed, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Create the data\n",
    "nsamples = 12000\n",
    "nfeat = 50\n",
    "\n",
    "x = 10. * np.random.random([nsamples, nfeat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time the `cdist` function and look the `top` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe here that the funcion `cdist` used to get the cityblock distance\n",
    "# is not multithreaded\n",
    "\n",
    "%timeit cdist(x, x, 'cityblock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `top` command we see that `cdist` runs in a single thread. In such cases it could be quite simple to write a distributed version of the function. You already know how to this! Let's use `dask.delayed`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask's async delayed execution\n",
    "A simple distributed version of `cdist` can be done as the following:\n",
    "  1. Split the array of vectors into chunks. We can use `np.split(x, num_chunks)`\n",
    "  2. Compute partial cityblock distance matrices of the complete array with respect to each of the chunks\n",
    "  3. Concatenate the resulting list into a single cityblock distance matrix.\n",
    "\n",
    "Note that concatenation is not a fast operation, so probably we will have to continue improving our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1. Split the array of vectors into chunks. We can use `np.split(x, num_chunks)`\n",
    "#  2. Compute partial cityblock distance matrices of the complete array with respect to each of the chunks\n",
    "\n",
    "chunks = 12  # define the number of operations to be performed asynchronously\n",
    "             # we choose one chunk per physical CPU (12 phyical CPUs in Pz Daint `gpu` partition)\n",
    "\n",
    "partial_distances = [cdist(x, xi, 'cityblock')\n",
    "                     for xi in np.split(x, chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the computational graph until this point\n",
    "visualize(partial_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdm = np.concatenate(partial_distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the computational graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have the computational graph already defined. Let's run and time the compute step. We may go a shell and run the command `top`. Now you should see that the computation is executed in parallel resulting in a shorter execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time and run the computational graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the resulting matrices are the same\n",
    "np.abs(cbdm - cdist(x, x, 'cityblock')).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with this solution, as mentioned above, is that `np.concatenate` is not  a fast operation.\n",
    "Let's check how much time it takes without the concatenation part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time and run the computational graph without the concatenate part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the whole thing as a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the whole thing as a single function\n",
    "def cityblock_dask(x, y, chunks):\n",
    "    \"\"\"Implementation using array concatenation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the resulting matrices are the same\n",
    "# print(np.abs(cityblock_dask(x, x, chunks) - cdist(x, x, 'cityblock')).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Question</mark>: Why is relevant for this implementation the fact that `scipy.spatial.distance.cdist` is not multithreaded?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhpc2020",
   "language": "python",
   "name": "pyhpc2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
